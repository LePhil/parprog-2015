\documentclass[8pt]{extarticle}
\usepackage{helvet}
\usepackage[T1]{fontenc}
\usepackage[a4paper,landscape,margin=0.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{xcolor}

\usepackage{listings}
\usepackage{tcolorbox}
\tcbuselibrary{breakable}
\tcbuselibrary{skins}
\usepackage{caption}
\usepackage{multicol}

\BeforeBeginEnvironment{lstlisting}{\begin{tcolorbox}[boxsep=-3mm]}
\AfterEndEnvironment{lstlisting}{\end{tcolorbox}}

\lstset{basicstyle=\tiny}

\renewcommand{\familydefault}{\sfdefault}

\let\oldtextbf\textbf
\renewcommand{\textbf}{\tiny\oldtextbf}

\parindent0pt

\begin{document}
\begin{multicols*}{5}
\textbf{[Java Thread]}
In Java können Threads mittels Vererbung hergestellt werden. Hierzu gibt es die Basisklasse \textbf{Thread}. Beim ableiten des von der Klasse muss nur \textbf{public void run()} überschrieben werden. Für den Start des Thread muss dann die Methode \textbf{start()} aufgerufen werden. EIN AUFRUF VON \textbf{run()} WÜRDE BLOCKIEREN!
\begin{lstlisting}[language=java]
class MyThread extends Thread {
  public void run() {
    do_something();
  }
}
//...
public static void main(String args[]) {
  (new MyThread()).start();
}
\end{lstlisting}
Des Weiteren gibt es das \textbf{Runnable} Interface, welches ähnlich dem Thread funktioniert. Es von einer Klasse implementiert werden. Auch hier muss die Methode \textbf{public void run()} überschrieben werden. Jedoch muss dann eine Instanz der neuen Klasse der Klasse Thread im Konstruktor übergeben werden.
\begin{lstlisting}[language=java]
class MyRunnable implements Runnable {
  public void run() {
    do_something();
  }
}
//...
public static void main(String args[]) {
  (new Thread(new MyRunnable())).start();
}
\end{lstlisting}
\textbf{Lambdas} sind eine weitere Möglichkeit um einen Thread zu erstellen. Hier wird dem Konstruktor von \textbf{Thread} ein Lambda übergeben.
\begin{lstlisting}[language=java]
public static void main(String args[]) {
  (new Thread(() -> {
    do_something();
  })).start();
}
\end{lstlisting}
Eine vierte Möglichkeit wäre eine \textbf{anonyme innere Klasse}.
\begin{lstlisting}[language=java]
public static void main(String args[]) {
  (new Thread(new Runnable() {
    @Override
    public void run() {
      do_something();
    }
  })).start();
}
\end{lstlisting}
Eine spezielle Art von Threads sind \textbf{Daemon Threads}. Diese Threads verhindern nicht das beenden des Programms. Der \textbf{Garbage Collector} ist ein solcher Thread.
\begin{lstlisting}[language=java]
public static void main(String args[]) {
  // ...
  someThread.setDaemon(true);
  someThread.start();
  // Wait for user input
  System.in.read();
}
\end{lstlisting}
Mit \textbf{Runtime.getRuntime().availableProcessors()} kann man bestimmen wieviele Prozessoren in einem System vorhanden sind. Die maximale Anzahl Threads errechnet sich aus dem verfügbaren Speicher des Systems und der grösse eines Threads. z.B. entsprechen ca. 110'000 Threads auf Windows 64-Bit in etwa 7GB Speicher. Bei Mehr Threads beginnt das System zu swappen und wird langsam.\\\\
\textbf{[synchronized]} Für einfachen (ineffizienten) \textbf{gegenseitigen Ausschluss} (mutual exclusion) gibt es das \textbf{synchronized} Schlüsselwort. Es muss vor dem Typ der Funktion angegeben werden. Der Auschluss via synchronized funktioniert mittels eines \textbf{Monitor-Locks} (siehe Monitor Object [POSA2]). Es kann immer nur ein Thread eine synchronized Methode auf einem Objekt ausführen. Alle anderen müssen warten \textbf{selbst wenn sie eine andere synchronized Methode aufrufen}. \textbf{synchronized} kann auch auf Block-level verwendet werden. Die Synchronisierung mittels \textbf{synchronized} ist \textbf{reentrant}, das heisst ein Thread kann mehrere \textbf{synchronized} Methoden verschachtelt aufrufen.
\begin{lstlisting}[language=java]
public class MyClass {
  public synchronized void syncMethOne(){
    dangerous_things();
  }

  public synchronized void syncMethTwo(){
    dangerous_things();
  }

  public void partlySync(){
    // do non dangerous stuff
    synchronized(this) {
      dangerous_things();
    }
  }
}
\end{lstlisting}
Da jedes Objekt ein \textbf{Monitor Lock} besitzt kann auf jedem Objekt ge\textbf{synchronized} werden (also auch auf Member-Objekten). Bedingungen sollten in \textbf{synchronized} Methoden mit \textbf{while} geprüft werden da sonst die gefahr besteht dass man fälschlicher Weisse weiter macht. Warten kann man mit \textbf{wait()} und notifizieren mit \textbf{notify} und \textbf{notifyAll()} wobei \textbf{notify()} \textbf{irgendeinen (!!!) wartenden Thread} weckt. FAUSTREGEL: Bei unterschiedlichen Wartebedingungen mit \textbf{notifyAll()} wecken.\\\\
\textbf{[Semphore]} sind "Zähler". Mit \textbf{acquire()} wird eine "Marke" entfernt, mit \textbf{release()} eine zurückgelegt. \textbf{acquire()} blockiert falls gerade keine "Marke" frei ist. \textbf{Semaphore} können fair sein (\textbf{new Semaphore(n, true)}) und folgen dan dem FIFO-Prinzip.\\\\
\textbf{[Locks \& Conditions]} können verwendet werden um ähnliche Funktionalität wie beim \textbf{Monitor} zu erreichen, mit dem grossen Unterschied, dass hier die Wartebedingungen gezielt "notifiziert" (via \textbf{signal()}) werden können. Jedem \textbf{Lock} können mehrere \textbf{Conditions} zugeordnet sein auf welche Threads via \textbf{await()} warten können.
\begin{lstlisting}[language=java]
public class MyClass {
  // fair lock
  private Lock mon = new ReentrantLock(true);
  // Conditions
  private Condition con1 = mon.newCondition();
  private Condition con2 = mon.newCondition();

  public void put(){
    mon.lock()
    try {
      while(canPut == false) {
        con1.await();
      }
      // do put
      con2.signal();
    } finally { mon.unlock(); }
  }

  public void get(){
    mon.lock()
    try {
      while(canGet == false) {
        con2.await();
      }
      // do put
      con1.signal();
    } finally { mon.unlock(); }
  }
}
\end{lstlisting}
\textbf{[Read-Write-Locks]} erlauben feingranulares Sperren. Da es nicht nötig ist zu sperren wenn alle Threads \textbf{nur lesen} können beliebig viele Threads gleichzeitig ein \textbf{Read-Lock} halten, jedoch \textbf{nur einer} ein \textbf{Write-Lock}. \textbf{Read-Write-Locks} können NICHT geupgraded werden.\\\\
\textbf{[CountdownLatch]} bietet einen "Einweg-Synchronisationspunkt". Bei der Initialisierung muss angegeben werden soll auf wieviele Threads gewartet wird. Threads verwenden \textbf{countDown()} auf dem Latch um den Zähler zu dekrementieren. Mit \textbf{await()} wird gewartet bis der Latch auf 0 ist. Der Latch kann nicht wiederverwendet werden.\\\\
\textbf{[CyclicBarrier]} ist ähnlich wie \textbf{CountdownLatch}. Aber \textbf{CyclicBarrier} kann wiederverwendet werden und wird bei \textbf{await()} dekrementiert. \textbf{getParties()} kann verwendet werden um die Anzahl Teilnahmer der Barriere auszulesen.\\\\
\textbf{[Phaser]} stellt eine verallgemeinerte \textbf{CyclicBarrier} dar. Mit \textbf{arriveAndAwaitAdvance()} wird auf die Freigabe gewartet. Threads können sich mit \textbf{register()} am Phaser an- und mit \textbf{arriveAndDeregister} abmelden.\\
\textbf{[Exchanger]} bietet eine Möglichkeit zwischen zwei Threads Objekte auszutauschen. \textbf{exchange(obj1)} wartet bis der andere Thread auch \textbf{exchange(obj2)} aufgerufen hat.\\\\
\textbf{[Race Conditions]} werden in \textbf{low-level (Data Race)} und \textbf{high-level (Semantic Race)} unterteilt. \textbf{Low-level} Races treten auf wenn unsynchronisiert auf den gleichen Speicher (Variable, Array-Element, ...) zugegriffen wird. \textbf{High-level} Races sind Race-Conditions in der Programmlogik. Sie Treten auf wenn die Critical-Sections nicht ausreichend geschützt sind.\\\\
Auf Synchronisierung kann verzichtet werden wenn entweder \textbf{Unveränderlichkeit} (z.B Java final) gegeben ist oder veränderlich Objekte in breits synchnosierten Objekten eingesperrt sind (\textbf{Confinement}).\\\\
\textbf{[Collections]} aus \textbf{java.util} sind grundsätzlich nicht Threadsafe. Es gibt jedoch Thread-Safe-Collections in \textbf{java.util.concurrent}.\\\\
\textbf{[Deadlocks]} treten auf wenn sich Threads gegenseitig sperren. Folgende Bedingungen müssen eintreten damit es einen Deadlock gibt: \textbf{Geschachtelte Locks} UND \textbf{Zyklische Warteabhängigkeiten} UND \textbf{Gegenseitiger Ausschluss} UND \textbf{Kein Timeout}. Deadlocks lassen sich durch Einführen einer \textbf{linearen Sperrordnung} oder \textbf{grobgranularer Sperrung} lösen.\\\\
\textbf{[Starvation]} tritt ein wenn einem Thread immer wieder die Möglichkeit zu laufen "weggeschnappt" wird. Dies lässt sich durch \textbf{faire} Synchronisationsprimitiven lösen.\\\\
\textbf{[Thread-Pools]} besitzen eine \textbf{Task Queue} in welcher Tasks eingereit und dann von einem freien \textbf{Worker Thread} bearbeitet werden. In Java erzeugt man \textbf{Thread Pools} mit der Factory Klasse \textbf{Executors}. Zur Auswahl stehen \textbf{newFixedThreadPool(nofThreads)}, \textbf{newChachedThreadPool()} (automatische Thread Zahl) und \textbf{newWorkStealingPool()}. Gesondert gibt es noch den \textbf{ForkJoinPool}, welcher es erlaubt rekursive Tasks zu formulieren. \textbf{Thread Pools} haben den Vorteil, dass nicht unnötig viele Threads erzeugt werden. Eine Einschränkung ist, dass Tasks nicht von einander abhängig sein dürfen da sonst eine \textbf{Deadlock}-Gefahr besteht. Der \textbf{ForkJoinPool} setzt im Gegensatz zu den anderen Pools \textbf{Daemon Thread}s ein. Tasks werden mittels des \textbf{Callable} Interfaces implementiert:
\begin{lstlisting}[language=java]
class CalcTask implements Callable<Integer> {
  @Override
  public Integer call() throws Exception {
    int val = 42;
    // long running stuff
    return val;
  }
}
ExecutorService pool =
  Executors.newFixedThreadPool(2);
Future<Integer> fut1, fut2;
// ...
fut1 = pool.submit(new CalcTask());
fut2 = pool.submit(new CalcTask());
// ...
int res1 = fut1.get();
int res2 = fut2.get();
// ...
pool.shutdown();
\end{lstlisting}
\textbf{[Futures]} repräsentieren Zukünftige Ergebnisse (sie sind Proxies im sinne des PROXY Patterns [GoF]) welche mittels \textbf{get()} abgeholt werden. \textbf{get()} blockiert bis das Ergebenis da ist! Wenn eine unbehandelte Exception aufgetreten ist liefert \textbf{get()} diese zurück geschachtelt in einer \textbf{ExecutionException}. Mittels \textbf{cancel()} kann ein Task aus der Warteschlange entfert werden (bricht aber nicht einfach den laufenden Task ab).\\\\
\textbf{[Work Stealing]} ist ein verfahren das in Thread Pools eingesetzt wird bei welchem es eine \textbf{globale FIFO} Queue und für jeden Worker Thread eine \textbf{locale LIFO} Queue gibt. Tasks in der globalen Queue werden (per Default) "vernachlässigt" aber der Work Stealing Pool kann auch auf FIFO umgestellt werden.\\\\
\textbf{[Asynchrone Aufrufe]} erlauben das Auslagern von langen Operationen auf einen anderen Thread oder Pool. Es gibt zwei ansätze: Caller-zentrisch (\textbf{pull}) und Callee-zentrisch (\textbf{push}). Pull setzt auf \textbf{Future} Objekte währen pull auf \textbf{Completion Callback}s setzt. Für Comletion Callbacks eignet sich als Interface zum Beispiel \textbf{java.util.function.Consumer}.
\begin{lstlisting}[language=java]
interface Consumer<T> {
  void accept(T result);
}
// ...
void asyncOp(int in, Consumer<Integer> cb) {
  pool.submit(() -> {
    Integer res = longOperation(in);
    cb.accept(res);
  });
}
// ...
asyncOp(42, res -> {
  System.out.println(res);
});
\end{lstlisting}
\textbf{[Continuations]} bieten in Java 8 eine Möglichkeit eine Folgeoperation an einen Task anzuhängen. Dazu verwendet man \textbf{CompletableFuture<T>}:
\begin{lstlisting}[language=java]
CompletableFuture<Long> fut = 
  CompletableFuture.supplyAsync(() -> longOp());
//...
fut.thenAccept(res -> System.out.println(res));
\end{lstlisting}
Die Continuation läuft auf dem Initiator \textbf{NUR WENN} die Future das Ergebnis schon hat, sonst auf einem beliebigen Worker Thread. Mittels \textbf{allOf()} und \textbf{any()} kann eine Continuation an mehrere Futures gebunden werden:
\begin{lstlisting}[language=java]
// wait for ALL Futures to arrive
CompletableFuture.allOf(fut1, fut2)
  .thenAccept(cont);
// wait for ANY Future to arrive
CompletableFuture.any(fut1, fut2)
  .thenAccept(cont);
\end{lstlisting}
\textbf{[.NET]} Threads "funtionieren" ähnlich wie Java Threads, nur ohne Vererbung sondern mit \textbf{Delegates} und mit dem Unterschied, dass \textbf{uncaught Exceptions} per Default zum \textbf{Programmabbruch} führen. Hier ein Threading-Beispiel mit einem Lambda:
\begin{lstlisting}[language=c++]
Thread myThread = new Thread(() => {
  for(int i = 0; i < 100; ++i)
    {
    Console.WriteLine("Step {0}", i);
    }
});
// ...
myThread.Start();
myThread.Join();
\end{lstlisting}
Im Gegensatz zu Java 8 können in .NET Lambdas auch \textbf{non-final} Variablen aus dem umgebenden Scope (via Referenzen) zugegriffen werden (AUCH SCHREIBEND!!!) was die Chance auf \textbf{low-level} Races erhöht.\\\\
\textbf{[Delegates]} sind vergleichbar mit Funktionszeigern welche ein implizites \textbf{this} besitzen. Sie sind damit leichgewichtiger als Java Interfaces, da sie keine Vererbungshierarchie aufweisen. Lambdas sind im Prinzip eine Abbildung von Delegates.\\\\
\textbf{[Monitor]} ist in .NET mittels des Schlüsselworts \textbf{lock} verfügbar, welches ähnlich wie \textbf{synchronized} vor einen Block gehängt wird. Als Best-Practice hat es sich eingebürgert ein Hilfsobjekt und nicht das eigene Objekt zu sperren. Zum warten und benachrichten werden \textbf{Monitor.Wait(lock)}, \textbf{Monitor.Pulse()} und \textbf{Monitor.PulseAll()} verwendet. Der .NET Monitor ist fair und \textbf{Pulse()} weckt immer den Thread der schon am längsten wartet.
\begin{lstlisting}[language=c++]
class Account {
  // ...
  private object syncObject = new object();

  public void syncOp1() {
    //...
    lock(syncObject) {
      dangerous_things();
      Monitor.PulseAll();
    }
  }
}
\end{lstlisting}
\textbf{[Andere Primitiven]} in .NET sind analog zu Java, ausser \textbf{Locks \& Conditions} welche fehlen und auch die fehelenden Fairness Flags. Dazu kommen \textbf{ReadWriteLockSlim} (upgradable), \textbf{Mutex} (binärer Semaphor) und speziellere. \textbf{Ausser} den Collections in \textbf{System.Collections.Concurrent} sind alle Collection NICHT Threadsafe.\\\\
\textbf{[TPL]} (Task Parallel Library) ist ein \textbf{Work Stealing Thread Pool} mit versciedenen Abstraktionsebenen (Task Parallelism, Data Parallelism, Asynchronous Programming with Continuations). Die \textbf{TPL} erkennt geschachtelte Task selber und es sind keine "speziellen" Vorkehrungen zu treffen. Des Weiteren spawned die \textbf{TPL} selber neue Threads wenn sie merkt das alle Threads blockiert sind. ACHTUNG: \textbf{TPL} Threads sind Background Threads (analog Java Daemon Threads). Via \textbf{ThreadPool.SetMaxThreads()} kann die maximale Anzahl Threads festgelegt werden -> \textbf{Deadlock}-Gefahr
\begin{lstlisting}[language=c++]
Task task1 = Task.Factory.StartNew(() => {
  // do stuff
});

// wait for task to finish
task1.Wait();

// tasks can have return values
Task<int> task2 = Task.Factory.StartNew(() => {
  int res = 42;
  return res;
});

// this blocks until task2 is finished
Console.WriteLine(task2.Result);
\end{lstlisting}
\textbf{[Exceptions]} in Tasks werden seit .NET 4.5 stillschweigend ingoriert und müssen explizit via den Event \textbf{TaskScheduler.UnobservedTaskException} aboniert werden.\\\\
\textbf{[Datenparallelität]} kann mittels Bordmitteln erreicht werden. Voraussetzung ist, dass die Unabhängigkeit der Daten gegeben ist! Nach dem Aufruf wird auf die Beendigung ALLER Tasks gewartet.
\begin{lstlisting}[language=c++]
Parallel.Invoke(
  () => Console.WriteLine("foo"),
  () => Console.WriteLine("bar")
);

Parallel.ForEach(list,
  entry => DoStuff(entry)
);

Parallel.For(0, arr.Length,
  idx => MoreStuff(arr[idx])
);
\end{lstlisting}
\textbf{[async/await]} erlauben das teil-asynchrone Ausführen von Funktionen. Der Compiler zerlegt die Funktion in zwei Hälften. Bis zum ersten blockierenden \textbf{await} wird die Funktion vom Caller ausgeführt. Der Rest wird auf einem \textbf{TPL}-Thread erledigt. \textbf{await} darf nur in Funktionen vorkommen die mit \textbf{async} gekennzeichtet sind und Funktionen die mit \textbf{async} gekennzeichnet sind MÜSSEN ein \textbf{await} enthalten! Das was nach dem await kommt ist die \textbf{Continuation}. Falls der Aufrufer \textbf{KEIN UI-Thread} auf einem \textbf{TPL-Thread} ausgeführt. Ist der Aufrufer ein \textbf{UI-Thread} dann wird die Continuation auf den \textbf{UI-Thread} dispatched. ACHTUNG: \textbf{async/await} kann zu einem Threadwechsel INNERHALB eines Funktionsaufrufs führen.
\begin{lstlisting}[language=c++]
class MainClass
  {
  public static async void DoStuff()
    {
    await Task.Delay(1000);
    Console.WriteLine("Knights!");
    }

  public static void Main(string[] args)
    {
    Console.WriteLine("foo");
    DoStuff();
    // In the meantime 'Knights!' gets
    // written to the console
    Thread.Sleep(5000);
    Console.WriteLine("bar");
    }
  }
\end{lstlisting}
\textbf{[Das Java Memory Model]} garantiert Atomicity für \textbf{Lese-/Schreiboperationen} bis 32-Bit (mit \textbf{volatile} auch für long und double) und auf Referenzen. Visibility ist bei Locks \textbf{Release/Acquire} garantiert (Änderungen vor Release werden bei Acquire sichtbar). Bei \textbf{volatile} Variablen werden alle vorhergehenden Änderungen beim Zugriff sichtbar. \textbf{final}-Variablen werden nach dem Ende des Konstruktors sichtbar. Sichtbarkeit ist auch bei Thread-Start und Join sowie Task-Start und Ende garantiert.\\\\
\textbf{[volatile in JAVA]} garantiert, dass kein Reordering über einen Zugriff (lesend oder schreibend) auf eine derart markierte Variable hinaus statt findet. Das Ordering vor und nach \textbf{volatile} folgt innerhalb eines Threads der "As-If-Serial"-Sematik, das heisst der Compiler darf optimieren falls die Semantik INNERHALB des Threads gleich bleibt. Zwischen Threads ist Ordering nur bei Zugriffen auf \textbf{volatile}-Variablen und bei Synchronisationsbefehlen garantiert. \textbf{volatile} Zugriffe führen nicht zu Locking.\\\\
\textbf{[Atomare Operationen]} erlauben das atomare Ändern einer Variablen mit einer Zusätzlichen Operation (meistens return des alten Werts). Es gibt für Atomare Klassen für Boolean, Integer, Long und Referenzen (auch für Array-Elemente). Seit Java 8 gibt es auf diesen sogar Operationen welche ein "Expression-Lambda" nehmen. \textbf{Atomare Operationen} garantieren Ordering und Visibility. Beispiele für atomare Operationen sind \textbf{getAndSet(newVal)}, \textbf{getAndAdd(delta)} und \textbf{updateAndGet(lambda)}.
\begin{lstlisting}[language=java]
public class SLock {
  private AtomicBoolean locked =
    new AtomicBoolean(false);

  public void acquire() {
    // spin if already locked
    // else set locked to true
    while(locked.getAndSet(true)) {
      Thread.yield();
    }
  }

  public void release() {
    // set false an make visible
    locked.set(false);
  }
}
\end{lstlisting}
\textbf{[compareAndSet(old, new)]} erlaubt das atomare prüfen ob die Variable einen bestimmten Wert hat und wenn ja diesen zu ersetzen. Es gibt zurück ob die Ersetzung stattgefunden hat. ACHTUNG: Hier kann man in das \textbf{ABA-Problem} laufen.
\begin{lstlisting}[language=java]
do {
  oldV = var.get();
  newV = calcChanges(oldV);
} while (!var.compareAndSet(oldV, newV));
\end{lstlisting}
\textbf{[Das ABA-Problem]} beschreibt was passiert wenn ein anderer Thread dazwischen schreibt aber sich der Wert den man vergleicht scheinbar nicht ändert. Dies ist Besonders bei lockfreien Datenstrukturen wie Stacks und listen ungünstig.
\textbf{[Das .NET Memory Model]} unterscheided sich vom Java Memory Model darin, dass long und double auch mit \textbf{volatile} nicht atomar sind. Auch die Visibility ist nicht explizit definiert, da sie durch das Ordering gegeben ist. Betreffst des Orderings ist es wichtig, das \textbf{volatile} in .NET nur eine "Partial Fence" ist.
\textbf{[volatile in .NET]} verfolgt beim Lesen die sogenannte \textbf{Acquire-Semantik}, was bedeutet, dass alles was \textbf{VOR dem LESEN} einer volatile Variable kommt nacht unten optimiert werden darf. Beim Schreiben wird die \textbf{Release-Semantik} angewandt. Die bedeutet, dass alles was \textbf{NACH dem SCHREIBEN} kommt nach oben optimiert werden darf. Da diese Semantik of ungenügend ist, gibt es mit \textbf{Thread.MemoryBarrier()} einen "Full-Fence".\\\\
\textbf{[GPU Vokabular]}: Eine GPU besteht aus mehreren \textbf{Streaming Multiprocessors (SM)}. Jeder SM besteht aus mehreren \textbf{Streaming Processors (SP)}. In CUDA sind Threads in \textbf{Blöcke} zusammengefasst. Jeder SM kann mehrere Blöcke beherbergen. Jeder Block ist intern in \textbf{Warp}s zu je 32 Threads zerlegt.\\\\
\textbf{[SIMD]} ist die Abkürzung für "Single Instruction Multiple Data". Dies entspricht dem Paradigma der Verktorparallelität. GPUs sind inherent für SIMD Applikationen geeignet denn innerhalb einen SM führen alle Cores die gleiche Instruktion auf unterschiedlichen Daten aus. Es gibt auch in CPU begrenzt mächtige SIMD Instruktionen.\\\\
\textbf{[CUDA]} ist die "Computer Unified Device Architecture" von nVidia. CUDA arbeitet mit sogenannten \textbf{Kernels} welche auf der GPU laufen. Jeder Kernel bekommt Informationen darüber auf welchem Block er läuft (\textbf{blockIdx.x}), welcher Thread innerhalb des Blocks er ist (\textbf{threadIdx.x}) und wie gross ein Block ist (\textbf{blockDim.x}). Auch die \textbf{y} und \textbf{z} Dimensionen sind nutzbar. Als Programmierer muss man die Datenauteilung selber modellieren.
\begin{lstlisting}[language=c]
// vector addition kernel
__global__
void vecAKern(float *A, float *B,
              float *C, int N) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  // bounds check
  if(i < N) {
    C[i] = A[i] + B[i];
  }
}
\end{lstlisting}
\textbf{[Das CUDA Memory Management]} kennt die drei wichtigen Funktionen \textbf{cudaMalloc}, \textbf{cudaFree} und \textbf{cudaMemcpy} welche ähnlich wie ihre C-Geschwister funktionieren. Mit \textbf{cudaMalloc} kann Speicher im \textbf{Device Global Memory} alloziert werden. \textbf{cudaFree} gibt allozierten Speicher auf dem Device wieder frei und \textbf{cudaMemcpy} wird verwendet um vom Host zum Device Daten zu kopieren.\\\\
Das "CUDA-Grundgerüst" ohne Error Handling sieht in etwa so aus:
\begin{lstlisting}[language=c]
void CudaVAdd(float* A, float* B,
              float* C, int N) {
  size_t size = N * sizeof(float);
  float *d_A, *d_B, *d_C;

  cudaMalloc(&d_A, size);
  cudaMalloc(&d_B, size);
  cudaMalloc(&d_C, size);

  cudaMemcpy(d_A, A, size,
             cudaMemcpyHostToDevice);
  cudaMemcpy(d_B, B, size,
             cudaMemcpyHostToDevice);
  
  int bDim = 512;
  int gDim = (N + blockDim - 1) / blockDim;
  vecAKern<<<gDim, bDim>>>(d_A, d_B, d_C, N);

  cudaMemcpy(C, d_C, size,
             cudaMemcpyDeviceToHost);

  cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
}
\end{lstlisting}
\textbf{[CUDA Function Keywords]} sind \textbf{\_\_global\_\_}(läuft auf Device wird von Host aufgerufen), \textbf{\_\_device\_\_}(läuft auf Device und wird von Device aufgerufen) und \textbf{\_\_host\_\_}(läuft auf Host und wird auch vom Host aufgerufen).\\\\
\textbf{[Die Launch-Configuration]} muss dynamisch bestimmt werden und sich am Problem und den Fähigkeiten des Device (ermittelt mit \textbf{cudaGetDeviceProperties()}) orientieren. Aus Effizienzgründen sollte die Blockgrösse ein Vielfaches von 32 sein (remember: 32 Threads per Warp, multiple Warps per Block). Die Blockgrösse sollte auch nicht zu gross gewählt werden, um die Anzahl der unnützen Threads zu minimieren. Die SM sollten voll ausgeschöpft werden (also ans Limit von Resident Blocks und Resident Threads gehen). Grosse Blöcke haben den vorteil, dass die Threads interagieren können.
\end{multicols*}
\end{document}
